#Canonical MyCHIPs JSON views of various tables and other JSON support
#Copyright MyCHIPs.org; See license in root of this package
#----------------------------------------------------------------
#TODO:
#- users_v.json should probably export nested addr/comm data too
#- Can I keep id and fk's out of these views and still insert data as needed?
#- 
module mychips
schema json {}

# View of users dedicated to JSON import
#----------------------------------------------------------------
view json.user_cert {json mychips.users_v} {select
    id		as "id"
  , peer_cid	as "cid"
  , peer_agent	as "agent"
  , ent_type	as "type"
  , peer_psig	as "public"
  , jsonb_build_object('surname', ent_name, 'first', fir_name, 'middle', mid_name, 'prefer', pref_name) as "name"
  , jsonb_build_object('country', country, 'id', tax_id) as "national"
    from mychips.users_v where not user_ent is null with cascaded check option;
} -primary {id}

# View of users dedicated to JSON import
#----------------------------------------------------------------
view json.user {json mychips.users_v} {select
    id		as "id"
  , peer_cid	as "cid"
  , ent_name	as "name"
  , ent_type	as "type"
  , fir_name	as "first"
  , mid_name	as "middle"
  , pref_name	as "prefer"
  , born_date	as "begin"
  , country	as "juris"
  , tax_id	as "taxid"
    from mychips.users_v where not user_ent is null with cascaded check option;
} -primary {id}

# View of addresses dedicated to JSON import
#----------------------------------------------------------------
view json.address {json base.addr_v} {select
    addr_ent	as "id"
  , addr_seq	as "seq"
  , addr_spec	as "spec"
  , addr_type	as "type"
  , addr_prim	as "main"
  , city	as "locale"
  , state	as "state"
  , pcode	as "post"
  , addr_cmt	as "comment"
  , addr_inact	as "prior"
    from base.addr_v where not addr_ent is null with cascaded check option;
} -primary {id seq}

# View of communication media dedicated to JSON import
#----------------------------------------------------------------
view json.connect {json base.comm_v} {select
    comm_ent	as "id"
  , comm_seq	as "seq"
  , comm_spec	as "spec"
  , comm_type	as "media"
  , comm_cmt	as "comment"
  , comm_inact	as "prior"
    from base.comm_v where not comm_ent is null with cascaded check option;
} -primary {id seq}

# Nested view of users dedicated to JSON export
#----------------------------------------------------------------
view json.users {json.user json.address json.connect} {select
  cid, name, type, first, middle, prefer, begin, juris, taxid
  , (select array_agg(to_jsonb(d)) from (select spec,type,main,locale,state,post,comment,prior from json.address a where a.id = u.id order by seq) d) as address
  , (select array_agg(to_jsonb(d)) from (select spec,media,comment,prior from json.connect c where c.id = u.id order by seq) d) as connect
    from json.user u;
} -primary {id}

# Standard view for tallies
#----------------------------------------------------------------
view json.tally {json mychips.tallies_v} {select
    tally_ent		as "id"
  , tally_guid		as "guid"
  , version		as "version"
  , case when tally_type = 'stock' then user_addr else part_addr end as "stock"
  , case when tally_type = 'stock' then part_addr else user_addr end as "foil"
  , tally_date		as "created"
  , contract		as "contract"

    from	mychips.tallies_v
} -primary {id seq}

# Standard view for tickets
#----------------------------------------------------------------
#view json.ticket {json mychips.tickets_v} {select
#    id			as "id"
#  , token_seq		as "seq"
#  , url			as "url"
#  , token		as "token"
#  , peer_psig		as "public"
#  , exp_date		as "expires"
#    from	mychips.tickets_v
#} -primary {id seq}

# Standard view for contracts
#----------------------------------------------------------------
view json.contract {json mychips.contracts_v} {select
    domain
  , name
  , version
  , language
  , published
  , title
  , text
  , tag
  , digest
  , sections
    from	mychips.contracts_v
} -primary {domain name version language}

# Import possibly nested JSON data structures
#----------------------------------------------------------------
function {json.import(data jsonb, target text default null, keys jsonb default null)} {json.user json.address json.connect json.tally} {
  returns record language plpgsql as $$
    declare
      tmpObject		jsonb;
      tableName		text;
      newRecord		record;
      fieldArray	text[];
      fieldList		text;
      primKeyList	text;
      cmd		text;
      tmpKey		text;
    begin
--raise notice 'Import:% data:%', target, data;
      if target isnull then						-- better be able to figure out target from key(s)
        for tableName in select jsonb_object_keys(data) loop		-- For each record in toplevel object
          tmpObject = data->tableName;					-- Recursively call for each property
          return json.import(tmpObject, tablename, keys);
        end loop;
      
      elsif jsonb_typeof(data) = 'array' then
        for tmpObject in select jsonb_array_elements(data) loop		-- Recursively call for each array element
          newRecord = json.import(tmpObject, target, keys);
        end loop;
        return newRecord;
        
      elsif jsonb_typeof(data) != 'object' then				-- Better be left with a single object
        return null;
      end if;

      select array_to_string(pkey,',') into primKeyList from wm.table_data where td_sch = 'json' and td_tab = target;
      if not found then return null; end if;			-- Skip any tables we don't know how to import
      
--raise notice '  process:% data:%', target, data;
      for tmpKey in select jsonb_object_keys(keys) loop		-- For any primary key values passed in from above
        data = jsonb_set(data, array[tmpkey], keys->tmpkey);	-- Assign them into our record
--raise notice '  setting key:%=% obj:%', tmpkey, keys->tmpkey, data;
      end loop;

      select array_agg(cdt_col), string_agg(quote_ident(cdt_col),',') into fieldArray, fieldList from wm.column_data where cdt_sch = 'json' and cdt_tab = target;
--raise notice '  fieldArray:% fieldList:%', fieldArray, fieldList;
      cmd = 'insert into json.' || quote_ident(target) || ' (' || fieldList || ') select ' || fieldList || ' from jsonb_populate_record(NULL::json.' || quote_ident(target) || ', $1) returning ' || primKeyList;
--raise notice '  cmd :% :%', cmd, data;
      execute cmd into newRecord using data;			-- Insert the record

--raise notice '  New PK:%', to_jsonb(newRecord);
      for tmpKey in select jsonb_object_keys(data) loop		-- Find any nested sub-objects that need to be inserted
        if not (tmpKey = any(fieldArray)) then
--raise notice '  ++Sub :%', tmpKey;
          perform json.import(data->tmpKey, tmpKey, to_jsonb(newRecord));	-- Recursive call
        end if;
      end loop;
      
--raise notice '  newRecord:%', newRecord;
      return newRecord;							-- Contains any newly created primary key
    end;
$$;}

#Canonical MyCHIPs JSON views of various tables and other JSON support
#Copyright MyCHIPs.org; See license in root of this package
#----------------------------------------------------------------
#TODO:
#- users_v.json should probably export nested addr/comm data too
#- Can I keep id and fk's out of these views and still insert data as needed?
#- 
module mychips
schema json {}

# View of users dedicated to JSON import
#----------------------------------------------------------------
view json.user {json mychips.users_v} {select
    id		as "id"
  , peer_cid	as "cid"
  , ent_name	as "name"
  , ent_type	as "type"
  , fir_name	as "first"
  , mid_name	as "middle"
  , pref_name	as "prefer"
  , born_date	as "begin"
  , peer_named	as "named"
  , country	as "juris"
  , tax_id	as "taxid"
    from mychips.users_v where not user_ent is null with cascaded check option;
} -primary {id}

# View of locations dedicated to JSON import
#----------------------------------------------------------------
view json.place {json base.addr_v} {select
    addr_ent	as "id"
  , addr_seq	as "seq"
  , addr_spec	as "address"
  , addr_type	as "type"
  , addr_prim	as "main"
  , city	as "city"
  , state	as "state"
  , pcode	as "post"
  , country	as "country"
  , addr_cmt	as "comment"
  , addr_inact	as "prior"
  , addr_priv	as "private"
    from base.addr_v where not addr_ent is null with cascaded check option;
} -primary {id seq}

# View of communication media dedicated to JSON import
#----------------------------------------------------------------
view json.connect {json base.comm_v} {select
    comm_ent	as "id"
  , comm_seq	as "seq"
  , comm_spec	as "address"
  , comm_type	as "media"
  , comm_prim	as "main"
  , comm_cmt	as "comment"
  , comm_inact	as "prior"
  , comm_priv	as "private"
    from base.comm_v where not comm_ent isnull with cascaded check option;
} -primary {id seq}

# Nested view of users dedicated to JSON export
#----------------------------------------------------------------
view json.users {json.user json.place json.connect} {select
  cid, name, type, first, middle, prefer, begin, juris, taxid
  , (select array_agg(to_jsonb(d)) from (select type,address,city,state,post,country,main,comment,prior from json.place p where p.id = u.id order by seq) d) as place
  , (select array_agg(to_jsonb(d)) from (select media,address,main,comment,prior from json.connect c where c.id = u.id order by seq) d) as connect
    from json.user u;
} -primary {id}

# Standard view for tallies
#----------------------------------------------------------------
view json.tally {json mychips.tallies_v} {select
    tally_ent		as "id"
  , tally_guid		as "guid"
  , version		as "version"
  , case when tally_type = 'stock' then user_addr else part_addr end as "stock"
  , case when tally_type = 'stock' then part_addr else user_addr end as "foil"
  , tally_date		as "created"
  , contract		as "contract"

    from	mychips.tallies_v
} -primary {id seq}

# Standard view for tickets
#----------------------------------------------------------------
#view json.ticket {json mychips.tickets_v} {select
#    id			as "id"
#  , token_seq		as "seq"
#  , url			as "url"
#  , token		as "token"
#  , peer_psig		as "public"
#  , exp_date		as "expires"
#    from	mychips.tickets_v
#} -primary {id seq}

# Standard view for contracts
#----------------------------------------------------------------
view json.contract {json mychips.contracts_v} {select
    domain
  , name
  , version
  , language
  , published
  , title
  , text
  , tag
  , digest
  , sections
    from	mychips.contracts_v
} -primary {domain name version language}

# View of users for generating/accepting user certificates
#----------------------------------------------------------------
view json.cert {mychips.users_v json.connect json.place} {select
    peer_cid	as "cid"
  , peer_agent	as "agent"
  , ent_type	as "type"
  , peer_psig	as "public"
  , case when ent_type = 'o' then
      to_jsonb(ent_name)
    else
      jsonb_strip_nulls(jsonb_build_object('surname', ent_name, 'first', fir_name, 'middle', mid_name, 'prefer', pref_name))
    end		as "name"
  , (select array_agg(jsonb_strip_nulls(to_jsonb(d))) from (
      select media,address,comment from json.connect c
        where c.id = u.id and not prior and not private and main order by seq
    ) d) as "connect"
  , (select array_agg(jsonb_strip_nulls(to_jsonb(d))) from (
      select type,address,city,state,post,country,comment from json.place p
        where not prior and not private and p.id = u.id and type != 'birth' and main order by seq
    ) d) as "place"
  , jsonb_strip_nulls(jsonb_build_object(
      'state', jsonb_strip_nulls(jsonb_build_object('country', country, 'id', tax_id)),
      'birth', jsonb_strip_nulls(jsonb_build_object(
        'name', u.peer_named,
        'date', u.born_date,
        'place', (select jsonb_strip_nulls(to_jsonb(d)) from (
          select address,city,state,post,country,comment from json.place a
            where a.id = u.id and type = 'birth' and main limit 1
        ) as d )
      ))
  )) as "identity"
  , current_timestamp::timestamptz(3) as "date"
  
    from mychips.users_v u where not user_ent is null with cascaded check option;
} -primary {cid agent}

# Write certificate data to its various tables
#----------------------------------------------------------------
function {json.cert_tf_ii()} {json.import(jsonb,text,jsonb)} {
  returns trigger language plpgsql security definer as $$
  declare
    ent_name text = new.name;
    fir_name text;
    mid_name text;
    pref_name text;
    born_date date;
    peer_named text;
    tax_id text;
    country text;
    irec record;
    ident jsonb = new.identity;
    birth_place jsonb;
    pkey jsonb;
  begin
--raise notice 'Cert:%', new;
    if (new.type = 'p') then				--Personal names
      ent_name = new.name->>'surname';
      fir_name = new.name->>'first';
      mid_name = new.name->>'middle';
      pref_name = new.name->>'prefer';
    end if;
    if not ident isnull then				--Identity records
      if not ident->'state' isnull then			--State ID
        tax_id = ident->'state'->>'id';
        country = ident->'state'->>'country';
      end if;
      if not ident->'birth' isnull then			--Birth ID
        birth_place = ident->'birth'->'place';
        born_date = (ident->'birth'->>'date')::date;
        peer_named = ident->'birth'->>'name';		--Birth name
      end if;
    end if;
    
    insert into mychips.users_v (ent_name, fir_name, mid_name, pref_name, ent_type, born_date, tax_id, country, peer_cid, peer_agent, peer_psig, peer_named)
      values (ent_name, fir_name, mid_name, pref_name, new.type, born_date, tax_id, country, new.cid, new.agent, new.public, peer_named)
      returning id into irec;

    pkey = to_jsonb(irec);
--raise notice 'pkey:%', pkey;
    perform json.import(to_jsonb(new.connect), 'connect', pkey);
    perform json.import(to_jsonb(new.place), 'place', pkey);
    if not birth_place isnull then
      birth_place = jsonb_set(birth_place, '{type}', '"birth"');
      perform json.import(birth_place, 'place', pkey);
    end if;

    return new;
  end;
$$;}
trigger json_cert_tf_ii {} {
    instead of insert on json.cert for each row execute procedure json.cert_tf_ii();
}

# Import possibly nested JSON data structures
#----------------------------------------------------------------
function {json.import(data jsonb, target text default null, keys jsonb default null)} {json.user json.place json.connect json.tally} {
  returns record language plpgsql as $$
    declare
      tmpObject		jsonb;
      tableName		text;
      newRecord		record;
      fieldArray	text[];
      fieldList		text;
      primKeyList	text;
      cmd		text;
      tmpKey		text;
    begin
--raise notice 'Import:% data:%', target, data;
      if target isnull then						-- better be able to figure out target from key(s)
        for tableName in select jsonb_object_keys(data) loop		-- For each record in toplevel object
          tmpObject = data->tableName;					-- Recursively call for each property
          return json.import(tmpObject, tablename, keys);
        end loop;
      
      elsif jsonb_typeof(data) = 'array' then
        for tmpObject in select jsonb_array_elements(data) loop		-- Recursively call for each array element
          newRecord = json.import(tmpObject, target, keys);
        end loop;
        return newRecord;
        
      elsif jsonb_typeof(data) != 'object' then				-- Better be left with a single object
        return null;
      end if;

      select array_to_string(pkey,',') into primKeyList from wm.table_data where td_sch = 'json' and td_tab = target;
      if not found then return null; end if;			-- Skip any tables we don't know how to import
      
--raise notice '  process:% data:%', target, data;
      for tmpKey in select jsonb_object_keys(keys) loop		-- For any primary key values passed in from above
        data = jsonb_set(data, array[tmpkey], keys->tmpkey);	-- Assign them into our record
--raise notice '  setting key:%=% obj:%', tmpkey, keys->tmpkey, data;
      end loop;

      select array_agg(cdt_col), string_agg(quote_ident(cdt_col),',') into fieldArray, fieldList from wm.column_data where cdt_sch = 'json' and cdt_tab = target;
--raise notice '  fieldArray:% fieldList:%', fieldArray, fieldList;
      cmd = 'insert into json.' || quote_ident(target) || ' (' || fieldList || ') select ' || fieldList || ' from jsonb_populate_record(NULL::json.' || quote_ident(target) || ', $1) returning ' || primKeyList;
--raise notice '  cmd :% :%', cmd, data;
      execute cmd into newRecord using data;			-- Insert the record

--raise notice '  New PK:%', to_jsonb(newRecord);
      for tmpKey in select jsonb_object_keys(data) loop		-- Find any nested sub-objects that need to be inserted
        if not (tmpKey = any(fieldArray)) then
--raise notice '  ++Sub :%', tmpKey;
          perform json.import(data->tmpKey, tmpKey, to_jsonb(newRecord));	-- Recursive call
        end if;
      end loop;
      
--raise notice '  newRecord:%', newRecord;
      return newRecord;							-- Contains any newly created primary key
    end;
$$;}
